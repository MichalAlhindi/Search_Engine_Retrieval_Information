{"cells":[{"cell_type":"markdown","metadata":{"id":"TJRE6WPXuc-h"},"source":["# Imports"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["NAME            PLATFORM  WORKER_COUNT  PREEMPTIBLE_WORKER_COUNT  STATUS   ZONE           SCHEDULED_DELETE\r\n","sean-cluster-7  GCE       4                                       RUNNING  us-central1-a\r\n"]}],"source":["!gcloud dataproc clusters list --region us-central1"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0m\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0m"]}],"source":["!pip install -q google-cloud-storage==1.43.0\n","!pip install -q graphframes"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["inverted_index_gcp.py\r\n"]}],"source":["%cd -q /home/dataproc\n","!ls inverted_index_gcp.py\n","from inverted_index_gcp import InvertedIndex"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"NBWmJzREuf9o"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0m\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0mPackage openjdk-8-jdk-headless is not available, but is referred to by another package.\n","This may mean that the package is missing, has been obsoleted, or\n","is only available from another source\n","\n","E: Package 'openjdk-8-jdk-headless' has no installation candidate\n","\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0m"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# import pyspark\n","# from google.cloud import storage\n","# from inverted_index_gcp import *\n","# import math\n","# import pickle\n","# from functools import reduce\n","# These will already be installed in the testing environment so disregard the \n","# amount of time (~1 minute) it takes to install. \n","!pip install -q pyspark\n","!pip install -U -q PyDrive\n","!apt install openjdk-8-jdk-headless -qq\n","!pip install -q graphframes\n","\n","\n","\n","import pyspark\n","import sys\n","from collections import Counter, OrderedDict, defaultdict\n","import itertools\n","from itertools import islice, count, groupby\n","import pandas as pd\n","import os\n","import re\n","from operator import itemgetter\n","import nltk\n","from nltk.stem.porter import *\n","from nltk.corpus import stopwords\n","from time import time\n","from pathlib import Path\n","import pickle\n","import numpy as np\n","import pandas as pd\n","import math\n","from functools import reduce\n","from google.cloud import storage\n","from inverted_index_gcp import *\n","\n","import hashlib\n","def _hash(s):\n","    return hashlib.blake2b(bytes(s, encoding='utf8'), digest_size=5).hexdigest()\n","\n","# ''' code addition'''\n","# from flask import Flask, request, jsonify\n","# ''' code addition'''\n","\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# Stopwords\n","english_stopwords = frozenset(stopwords.words('english'))\n","corpus_stopwords = [\"category\", \"references\", \"also\", \"external\", \"links\", \n","                    \"may\", \"first\", \"see\", \"history\", \"people\", \"one\", \"two\", \n","                    \"part\", \"thumb\", \"including\", \"second\", \"following\", \n","                    \"many\", \"however\", \"would\", \"became\"]\n","RE_WORD = re.compile(r\"\"\"[\\#\\@\\w](['\\-]?\\w){2,24}\"\"\", re.UNICODE)\n","all_stopwords = english_stopwords.union(corpus_stopwords)"]},{"cell_type":"markdown","metadata":{"id":"KAqN15K99rFV"},"source":["# Query Preparation"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"vF04Zo60-Od7"},"outputs":[],"source":["# tokenize & remove stop words.\n","def tokenize_and_remove_sw(text):\n","  tokens = [token.group() for token in RE_WORD.finditer(text.lower())]\n","  return [x for x in tokens if x not in all_stopwords]\n","\n","# stemming  \n","def stemming(tokens):\n","  stemmer = PorterStemmer()\n","  return [stemmer.stem(x) for x in tokens]\n","\n","# reading postinglist"]},{"cell_type":"markdown","metadata":{"id":"jaHwYg09Doq4"},"source":["# Index Preparation"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"roHGps-CDvD_"},"outputs":[],"source":["TUPLE_SIZE = 6       \n","TF_MASK = 2 ** 16 - 1 # Masking the 16 low bits of an integer\n","from contextlib import closing\n","\n","def read_posting_list(inverted, w, bucket_name):\n","  with closing(MultiFileReader()) as reader:\n","    locs = inverted.posting_locs[w]\n","    b = reader.read(locs, inverted.df[w] * TUPLE_SIZE, bucket_name)\n","    posting_list = []\n","    for i in range(inverted.df[w]):\n","      doc_id = int.from_bytes(b[i*TUPLE_SIZE:i*TUPLE_SIZE+4], 'big')\n","      tf = int.from_bytes(b[i*TUPLE_SIZE+4:(i+1)*TUPLE_SIZE], 'big')\n","      posting_list.append((doc_id, tf))\n","    return posting_list\n"]},{"cell_type":"markdown","metadata":{"id":"wB0maAze20_F"},"source":["# Search"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z3vdf-Zy3VCB"},"outputs":[],"source":["# def search(query):\n","#     res = []\n","#     # query = request.args.get('query', '')\n","#     # if len(query) == 0:\n","#     #   return jsonify(res)\n","#     # BEGIN SOLUTION\n","#     tokens = tokenize_and_remove_sw(query)\n","#     stemmed_tokens = stemming(tokens)\n","#     title_results = ''' we call the search title function and give it our query & title index'''\n","#     body_results = ''' we call the search body function and give it our query & body index'''\n","#     anchor_results = ''' we call the search anchor function and give it our query & anchor index'''\n","\n","#     ''' we normalize the 3 ranks & using getTopN (N=100)'''\n","\n","#     '''we merge all the results into 1 list of tuples of (doc_id, title)'''\n","\n","#     # END SOLUTION\n","#     return jsonify(res)"]},{"cell_type":"markdown","metadata":{"id":"KY1UbZ4e_DSz"},"source":["## Search Title "]},{"cell_type":"code","execution_count":12,"metadata":{"id":"jZTkB8qwtV8Y"},"outputs":[],"source":["# loading inverted index from title bucket\n","client = storage.Client()\n","my_bucket = client.bucket('sean_bucket_title')\n","idx_title = pickle.loads(my_bucket.get_blob('postings_gcp/index_title.pkl').download_as_string())"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"DcxTEXNI_HkH"},"outputs":[],"source":["def search_title(query):\n","    res = []\n","    # if len(query) == 0:\n","    #   return jsonify(res)\n","    filtered_query = tokenize_and_remove_sw(query)\n","    all_posting_lists = {}\n","    for term in np.unique(filtered_query):\n","      if term in idx_title.df:\n","        try:\n","            res = read_posting_list(idx_title, term, 'sean_bucket_title')\n","            for doc_id, amount in res:\n","                try:\n","                    all_posting_lists[doc_id] += 1\n","                except:\n","                    all_posting_lists[doc_id] = 1\n","        except Exception as e:\n","            print('error in title index occured - ', e)\n","    res= sorted(all_posting_lists, key=all_posting_lists.get, reverse=True)\n","    res = [(id, idx_title.title_dict[id]) for id in res]\n","    return(res)\n","    # return jsonify(res)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"lglKqDxXVJ0c","outputId":"580b61b3-ab76-4f3b-af2b-90b2cf13b125"},"outputs":[{"name":"stdout","output_type":"stream","text":["[(970755, 'LinkedIn'), (27769500, 'LinkedIn Pulse'), (36070366, '2012 LinkedIn hack'), (41726116, 'LinkedIn Learning'), (50191962, 'Timeline of LinkedIn'), (57147095, 'LinkedIn Top Companies'), (62976368, 'HiQ Labs v. LinkedIn')]\n"]}],"source":["# print(read_posting_list(idx_title, \"alabama\",bucket_name_title))\n","print(search_title(\"linkedin\"))"]},{"cell_type":"markdown","metadata":{"id":"MOMJ_RR0Kf-q"},"source":["## Search Body"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K5zM-4QpMl-t"},"outputs":[],"source":["# loading inverted index from body bucket\n","my_bucket = client.bucket('sean_bucket_body')\n","idx_body = pickle.loads(my_bucket.get_blob('postings_gcp/index_b.pkl').download_as_string())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7EZzRstMNFU9"},"outputs":[],"source":["# Cosine_Similarity {id:cosine score}\n","def cosine_similarity(search_query, index):\n","    \"\"\" Returns: {id:cosine score} \"\"\"\n","    dict_cosine_sim = {}\n","    # idx_body.nf = math.sqrt(sum([index.tf[x]**2 for x in search_query]))\n","    for term in search_query:\n","      if term in index.df.keys():\n","        pos_lst = read_posting_list(index,term)\n","        for d, t in pos_lst:\n","          if d in dict_cosine_sim.keys():\n","            dict_cosine_sim[d] += index.df[term]*t\n","          else:\n","            dict_cosine_sim[d] = index.df[term]*t\n","    for d in dict_cosine_sim.keys():\n","      dict_cosine_sim[d] *= (1/len(search_query) * index.nf[d])\n","    return dict_cosine_sim\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ifwhj-wxB5q5"},"outputs":[],"source":["# get list of top N ranked pairs (doc_id, score)\n","def get_top_n(sim_dict,N=3):\n","  return sorted([(doc_id,score) for doc_id, score in sim_dict.items()], key = lambda x: x[1],reverse=True)[:N]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pGdDKkgIhJbx"},"outputs":[],"source":["def search_body(query):\n","    filtered_query = tokenize_and_remove_sw(query)\n","    cos_dct = cosine_similarity(filtered_query,idx_body)\n","    res = get_top_n(cos_dct,100)\n","    return [(id[0], idx_body.title_dict[id[0]]) for id in res]\n","  \n","    # res = []\n","    # query = request.args.get('query', '')\n","    # if len(query) == 0:\n","    #   return jsonify(res)\n","    # return jsonify(res)"]},{"cell_type":"markdown","metadata":{"id":"EsVRO0y_7lt0"},"source":["## Search Anchor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x5VS1zjv7vN1"},"outputs":[],"source":["def search_anchor(query):\n","  res = []\n","\n","  # if len(query) == 0:\n","  #   return jsonify(res)\n","  filtered_query = tokenize_and_remove_sw(query)\n","  all_posting_lists = {}\n","  for term in np.unique(filtered_query):\n","    if term in idx_anchor.df:\n","      try:\n","          res = read_posting_list(idx_anchor, term)\n","          for doc_id, amount in res:\n","              try:\n","                  all_posting_lists[doc_id] += 1\n","              except:\n","                  all_posting_lists[doc_id] = 1\n","      except Exception as e:\n","          print('error in anchor index occured - ', e)\n","  res= sorted(all_posting_lists, key=all_posting_lists.get, reverse=True)\n","  \n","  res = [(id, idx_anchor.title_dict[id]) for id in res if id in idx_anchor.title_dict]\n","  return res\n","  # return jsonify(res)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"}},"nbformat":4,"nbformat_minor":1}